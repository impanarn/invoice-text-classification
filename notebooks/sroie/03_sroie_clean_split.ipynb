{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "\n",
    "BASE_PATH = r\"C:\\Users\\Impana\\Downloads\\invoice-classification\\\\\"\n",
    "OUT_PATH = os.path.join(BASE_PATH, \"data\", \"sroie\", \"D01_sroie_sectors.csv\")\n",
    "\n",
    "df.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved:\", OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = str(text).lower().strip()\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = ' '.join(w for w in text.split() if len(w) > 1)\n",
    "    text = ' '.join(w for w in text.split() if w not in stop_words)\n",
    "    text = ' '.join(w for w in text.split() if wordnet.synsets(w))\n",
    "    return text.strip()\n",
    "\n",
    "df = pd.read_csv(OUT_PATH)\n",
    "df['text_clean'] = df['text'].apply(clean_text)\n",
    "df = df[df['text_clean'].str.len() > 0].drop_duplicates()\n",
    "\n",
    "print(df.shape, df['category'].value_counts())\n",
    "clean_path = os.path.join(BASE_PATH, \"data\", \"sroie\", \"D02_sroie_cleaned.csv\")\n",
    "df.to_csv(clean_path, index=False)\n",
    "print(\"Saved:\", clean_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e23209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(clean_path)\n",
    "\n",
    "df = df.groupby('category').filter(lambda x: len(x) > 1)\n",
    "print(\"After dropping single-instance classes:\", df['category'].value_counts())\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.15,\n",
    "    stratify=df['category'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Test:\", test_df.shape)\n",
    "train_path = os.path.join(BASE_PATH, \"data\", \"sroie\", \"D2_sroie_train.csv\")\n",
    "test_path  = os.path.join(BASE_PATH, \"data\", \"sroie\", \"D2_sroie_test.csv\")\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "print(\"Saved train/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def augment_label(label_text: str) -> str:\n",
    "    words = clean_text(label_text).split()\n",
    "    if len(words) == 0:\n",
    "        return \"\"\n",
    "    if len(words) == 1:\n",
    "        return words[0]\n",
    "    op = np.random.choice(['swap', 'drop'])\n",
    "    if op == 'swap' and len(words) >= 2:\n",
    "        i, j = np.random.choice(len(words), 2, replace=False)\n",
    "        words[i], words[j] = words[j], words[i]\n",
    "    elif op == 'drop':\n",
    "        k = np.random.randint(len(words))\n",
    "        words.pop(k)\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "aux_words = []\n",
    "for lbl in train_df['category']:\n",
    "    aug = augment_label(lbl)\n",
    "    tokens = aug.split()\n",
    "    aux_words.append(tokens[np.random.randint(len(tokens))] if tokens else \"\")\n",
    "\n",
    "train_df['aux_word'] = aux_words\n",
    "train_df['text_enriched'] = (train_df['text_clean'] + \" \" + train_df['aux_word']).str.strip()\n",
    "\n",
    "d3 = pd.concat(\n",
    "    [\n",
    "        train_df[['text_clean', 'category']].rename(columns={'text_clean': 'text'}),\n",
    "        train_df[['text_enriched', 'category']].rename(columns={'text_enriched': 'text'})\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(\"D3 shape:\", d3.shape)\n",
    "d3_path = os.path.join(BASE_PATH, \"data\", \"sroie\", \"D3_sroie_train.csv\")\n",
    "d3.to_csv(d3_path, index=False)\n",
    "print(\"Saved:\", d3_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
